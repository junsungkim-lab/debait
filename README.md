# ğŸ¤– Multi-Agent Workflow (Debait)

> **Multiple AIs debate each other. One refined answer wins.**

Instead of asking one AI, this runs a structured debate pipeline: a **Solver** proposes, a **Critic** attacks, a **Checker** verifies, and a **Synth** delivers the final refined answer â€” all in your browser, no login required. Roles and models are **fully customizable**.

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![BYOK](https://img.shields.io/badge/BYOK-5%20Providers-6366f1)](https://github.com/junsungkim-lab/multi-agent-workflow)

**ğŸŒ Language:** English | [í•œêµ­ì–´](README.ko.md) | [ä¸­æ–‡](README.zh.md)

---

![Architecture](assets/architecture.png)

---

## âš¡ Quickstart (Python only, no Docker needed)

```bash
git clone https://github.com/junsungkim-lab/multi-agent-workflow.git
cd multi-agent-workflow
pip install -r requirements.txt
cp .env.example .env          # fill in your keys (see below)
uvicorn app.main:app --port 8000
```

Open `http://localhost:8000` â†’ Settings â†’ Add your API key â†’ Ask anything.

> Local Python run stores data in `./app.db` by default.
> Docker/Kubernetes examples use `/data/app.db` for persistent volumes.

---

## ğŸ¯ Why Multi-Agent Workflow?

Most AI tools give you **one model's answer**. This gives you a **peer-reviewed answer**.

| | Single ChatGPT | AutoGen / CrewAI | **Multi-Agent Workflow** |
|--|--|--|--|
| Setup | Instant | Complex config | **3 commands** |
| Debate roles | âŒ | Custom agents | **Built-in + fully customizable** |
| Web UI | âŒ | âŒ | **âœ… Included** |
| Telegram | âŒ | âŒ | **âœ… Built-in** |
| BYOK | âŒ | âŒ | **âœ… 5 Providers** |
| Mix models per role | âŒ | Partial | **âœ… Any role = any model** |
| Custom pipeline stages | âŒ | Code only | **âœ… UI editor** |

---

## ğŸ’¡ Use Cases

- **Engineering decisions** â€” "Should we use microservices or monolith for this stage?"
- **Code review** â€” Paste code, get Solver + Critic + Checker perspective
- **Research synthesis** â€” Compare arguments on any topic
- **Writing** â€” Draft â†’ critique â†’ final polished version
- **Risk analysis** â€” Any plan gets automatically stress-tested by Critic

---

## ğŸ”§ Supported AI Providers

| Provider | Get Key | Cheap Model | Quality Model |
|----------|---------|-------------|---------------|
| **OpenAI** | [platform.openai.com](https://platform.openai.com/api-keys) | `openai:gpt-4o-mini` | `openai:gpt-4o` |
| **Anthropic** | [console.anthropic.com](https://console.anthropic.com/settings/keys) | `anthropic:claude-haiku-4-5-20251001` | `anthropic:claude-sonnet-4-6` |
| **Google Gemini** | [aistudio.google.com](https://aistudio.google.com/apikey) | `google:gemini-2.0-flash` | `google:gemini-2.5-pro-preview-05-06` |
| **Groq** | [console.groq.com](https://console.groq.com/keys) | `groq:llama-3.1-8b-instant` | `groq:llama-3.3-70b-versatile` |
| **Mistral** | [console.mistral.ai](https://console.mistral.ai/api-keys) | `mistral:mistral-small-latest` | `mistral:mistral-medium-latest` |

Each **role can use a different provider** â€” mix and match for cost vs quality.

---

## ğŸ—ï¸ How It Works

```
Your Question
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1â”‚â”€â”€â”€â–¶â”‚  Stage 2â”‚â”€â”€â”€â–¶â”‚  Stage Nâ”‚â”€â”€â”€â–¶â”‚  Synth  â”‚
â”‚         â”‚    â”‚         â”‚    â”‚         â”‚    â”‚         â”‚
â”‚Proposes â”‚    â”‚ Attacks â”‚    â”‚Verifies â”‚    â”‚ Final   â”‚
â”‚solution â”‚    â”‚ & risks â”‚    â”‚& fixes  â”‚    â”‚ answer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚               â”‚               â”‚
  any LLM         any LLM         any LLM         any LLM
```

- Pipeline stages are **fully customizable** via the Settings UI (add / remove / reorder, max 6)
- Each stage has its own **name**, **system prompt**, and **model**
- Synth always runs last, synthesizing all stage outputs into one final answer
- Simple questions skip intermediate stages for speed and cost efficiency

---

## ğŸš€ Full Setup

### 1. Environment Variables

```bash
cp .env.example .env
```

| Variable | Required | Description |
|----------|----------|-------------|
| `MASTER_KEY` | âœ… | Fernet key to encrypt stored API keys |
| `WEBHOOK_SECRET` | Web + Telegram | Secret path for Telegram webhook |
| `TELEGRAM_BOT_TOKEN` | Web + Telegram | From [@BotFather](https://t.me/BotFather) |
| `BASE_URL` | âœ… | Your app's public URL (e.g. `http://localhost:8000`) |
| `DB_URL` | Optional | Defaults to `sqlite:///./app.db` (local) |

Generate keys:
```bash
# MASTER_KEY
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# WEBHOOK_SECRET
python -c "import secrets; print(secrets.token_urlsafe(48))"
```

### 2. Add Your API Key

Go to `http://localhost:8000/settings` â†’ paste your key.
Keys are **encrypted at rest** using your `MASTER_KEY` â€” never stored in plaintext.

### 3. Configure Pipeline (Optional)

Settings â†’ Debate Pipeline â†’ add / remove / reorder stages, assign any model per stage.

```
Stage 1 (Solver)  â†’ anthropic:claude-sonnet-4-6   # quality answer
Stage 2 (Critic)  â†’ openai:gpt-4o-mini            # cheap critique
Stage 3 (Checker) â†’ openai:gpt-4o-mini            # cheap verify
Synth             â†’ anthropic:claude-sonnet-4-6   # quality final
```

---

## ğŸ³ Docker

```bash
docker compose up --build
```

Uses `DB_URL=sqlite:////data/app.db` and mounts `./data` to `/data`.

## â˜¸ï¸ Kubernetes

```bash
cp application.yaml.example application.yaml
# Fill in your secrets, then:
docker build -t debait:latest .
kubectl apply -f application.yaml
# Open http://localhost:30090
```

`application.yaml.example` includes `DB_URL=sqlite:////data/app.db` and mounts `/data` via PVC.

---

## ğŸ“ Project Structure

```
multi-agent-workflow/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # FastAPI routes
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ runner.py            # Dynamic pipeline engine
â”‚   â”‚   â”œâ”€â”€ prompts.py           # Synth system prompt
â”‚   â”‚   â””â”€â”€ router.py            # SIMPLE vs MULTI routing
â”‚   â”œâ”€â”€ providers/               # OpenAI, Anthropic, Google, Groq, Mistral
â”‚   â””â”€â”€ templates/               # Server-side HTML UI
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ set_webhook.py           # Register Telegram webhook
â”‚   â””â”€â”€ delete_webhook.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ application.yaml.example     # Kubernetes template
```

---

## ğŸ”’ Security & Privacy

- API keys are **encrypted with Fernet (AES-128-CBC)** before storage
- Keys never leave your server
- No analytics, no telemetry
- SQLite database stays **local** â€” your conversations are yours
- `MASTER_KEY` loss = encrypted keys unrecoverable (by design)

---

## ğŸ—ºï¸ Roadmap

- [ ] Streaming responses (real-time debate display)
- [ ] Export conversation as Markdown/PDF
- [ ] Multi-round debate (iterative refinement)
- [ ] RAG support (attach documents to questions)
- [ ] REST API for programmatic access

---

## ğŸ¤ Contributing

PRs welcome. For major changes, open an issue first.

```bash
git checkout -b feature/your-feature
# make changes
git push origin feature/your-feature
# open PR
```

---

## ğŸ“„ License

MIT â€” use it, fork it, build on it.

---

*If this saved you from a bad decision, consider leaving a â­ â€” it helps others find this project.*
