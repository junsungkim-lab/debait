# ğŸ¤– Debait â€” Multi-AI Debate Engine

> **Multiple AIs argue. One best answer wins.**

Instead of asking one AI, Debait runs a structured debate: a **Solver** proposes, a **Critic** attacks, a **Checker** verifies, and a **Synth** delivers the final refined answer â€” all in your browser, no login required.

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![BYOK](https://img.shields.io/badge/BYOK-5%20Providers-6366f1)](https://github.com/junsungkim-lab/debait)

**ğŸŒ Language:** English | [í•œêµ­ì–´](README.ko.md) | [ä¸­æ–‡](README.zh.md)

---

![Architecture](assets/architecture.png)

---

## âš¡ Quickstart (Python only, no Docker needed)

```bash
git clone https://github.com/junsungkim-lab/debait.git
cd debait
pip install -r requirements.txt
cp .env.example .env          # fill in your keys (see below)
uvicorn app.main:app --port 8000
```

Open `http://localhost:8000` â†’ Settings â†’ Add your API key â†’ Ask anything.

> Data (conversations, API keys) is saved to `app.db` locally and persists across restarts.

---

## ğŸ¯ Why Debait?

Most AI tools give you **one model's answer**. Debait gives you a **peer-reviewed answer**.

| | Single ChatGPT | AutoGen / CrewAI | **Debait** |
|--|--|--|--|
| Setup | Instant | Complex config | **3 commands** |
| Debate roles | âŒ | Custom agents | **Built-in (Solver/Critic/Checker/Synth)** |
| Web UI | âŒ | âŒ | **âœ… Included** |
| Telegram | âŒ | âŒ | **âœ… Built-in** |
| BYOK | âŒ | âŒ | **âœ… 5 Providers** |
| Mix models per role | âŒ | Partial | **âœ… Any role = any model** |

---

## ğŸ’¡ Use Cases

- **Engineering decisions** â€” "Should we use microservices or monolith for this stage?"
- **Code review** â€” Paste code, get Solver + Critic + Checker perspective
- **Research synthesis** â€” Compare arguments on any topic
- **Writing** â€” Draft â†’ critique â†’ final polished version
- **Risk analysis** â€” Any plan gets automatically stress-tested by Critic

---

## ğŸ”§ Supported AI Providers

| Provider | Get Key | Cheap Model | Quality Model |
|----------|---------|-------------|---------------|
| **OpenAI** | [platform.openai.com](https://platform.openai.com/api-keys) | `openai:gpt-4o-mini` | `openai:gpt-4o` |
| **Anthropic** | [console.anthropic.com](https://console.anthropic.com/settings/keys) | `anthropic:claude-haiku-4-5-20251001` | `anthropic:claude-sonnet-4-6` |
| **Google Gemini** | [aistudio.google.com](https://aistudio.google.com/apikey) | `google:gemini-2.0-flash` | `google:gemini-2.5-pro-preview-05-06` |
| **Groq** | [console.groq.com](https://console.groq.com/keys) | `groq:llama-3.1-8b-instant` | `groq:llama-3.3-70b-versatile` |
| **Mistral** | [console.mistral.ai](https://console.mistral.ai/api-keys) | `mistral:mistral-small-latest` | `mistral:mistral-medium-latest` |

Each **role can use a different provider** â€” mix and match for cost vs quality.

---

## ğŸ—ï¸ How It Works

```
Your Question
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Solver â”‚â”€â”€â”€â–¶â”‚  Critic â”‚â”€â”€â”€â–¶â”‚ Checker â”‚â”€â”€â”€â–¶â”‚  Synth  â”‚
â”‚         â”‚    â”‚         â”‚    â”‚         â”‚    â”‚         â”‚
â”‚Proposes â”‚    â”‚ Attacks â”‚    â”‚Verifies â”‚    â”‚ Final   â”‚
â”‚solution â”‚    â”‚ & risks â”‚    â”‚& fixes  â”‚    â”‚ answer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚               â”‚               â”‚
  any LLM         any LLM         any LLM         any LLM
```

Each role can use a **different model** (e.g., Solver=GPT-4o, Critic=Claude Sonnet, Synth=Claude Haiku).
Simple questions skip directly to Solver â†’ Synth for speed and cost efficiency.

---

## ğŸš€ Full Setup

### 1. Environment Variables

```bash
cp .env.example .env
```

| Variable | Required | Description |
|----------|----------|-------------|
| `MASTER_KEY` | âœ… | Fernet key to encrypt stored API keys |
| `WEBHOOK_SECRET` | âœ… | Secret path for Telegram webhook |
| `TELEGRAM_BOT_TOKEN` | âœ… | From [@BotFather](https://t.me/BotFather) |
| `BASE_URL` | âœ… | Your app's public URL (e.g. `http://localhost:8000`) |

Generate keys:
```bash
# MASTER_KEY
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# WEBHOOK_SECRET
python -c "import secrets; print(secrets.token_urlsafe(48))"
```

### 2. Add Your API Key

Go to `http://localhost:8000/settings` â†’ paste your OpenAI or Anthropic key.
Keys are **encrypted at rest** using your `MASTER_KEY` â€” never stored in plaintext.

### 3. Configure Models (Optional)

Mix and match any model per role in Settings:

```
Solver  â†’ anthropic:claude-sonnet-4-6   # quality answer
Critic  â†’ openai:gpt-4o-mini            # cheap critique
Checker â†’ openai:gpt-4o-mini            # cheap verify
Synth   â†’ anthropic:claude-sonnet-4-6   # quality final
```

---

## ğŸ³ Docker

```bash
docker compose up --build
```

## â˜¸ï¸ Kubernetes

```bash
cp application.yaml.example application.yaml
# Fill in your secrets, then:
docker build -t debait:latest .
kubectl apply -f application.yaml
# Open http://localhost:30090
```

---

## ğŸ“ Project Structure

```
debait/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                  # FastAPI routes
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ runner.py            # Debate engine (Solverâ†’Criticâ†’Checkerâ†’Synth)
â”‚   â”‚   â”œâ”€â”€ prompts.py           # Role-specific system prompts
â”‚   â”‚   â””â”€â”€ router.py            # SIMPLE vs MULTI routing
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”‚   â””â”€â”€ anthropic_provider.py
â”‚   â””â”€â”€ templates/               # Server-side HTML UI
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ set_webhook.py           # Register Telegram webhook
â”‚   â””â”€â”€ delete_webhook.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ application.yaml.example     # Kubernetes template
```

---

## ğŸ”’ Security & Privacy

- API keys are **encrypted with Fernet (AES-128-CBC)** before storage
- Keys never leave your server
- No analytics, no telemetry
- SQLite database stays **local** â€” your conversations are yours
- `MASTER_KEY` loss = encrypted keys unrecoverable (by design)

---

## ğŸ—ºï¸ Roadmap

- [ ] Streaming responses (real-time debate display)
- [ ] Custom role prompts via UI
- [ ] Export conversation as Markdown/PDF
- [ ] Multi-round debate (iterative refinement)
- [ ] RAG support (attach documents to questions)
- [ ] REST API for programmatic access

---

## ğŸ¤ Contributing

PRs welcome. For major changes, open an issue first.

```bash
git checkout -b feature/your-feature
# make changes
git push origin feature/your-feature
# open PR
```

---

## ğŸ“„ License

MIT â€” use it, fork it, build on it.

---

*If Debait saved you from a bad decision, consider leaving a â­ â€” it helps others find this project.*
